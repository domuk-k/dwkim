# Render Production Environment

# Server Configuration
PORT=10000
NODE_ENV=production
LOG_LEVEL=info

# LLM Configuration
OPENAI_MODEL=gpt-4o-mini

# Rate Limiting (과금 방지)
RATE_LIMIT_MAX=8  # 분당 8회
RATE_LIMIT_WINDOW_MS=60000

# OpenAI API 보호
MAX_TOKENS=500   # 토큰 수 제한
TEMPERATURE=0.7  # 일정한 응답

# Mock 모드 (벡터 DB 없이 실행)
MOCK_MODE=true
USE_VECTOR_STORE=false

# Redis는 Render에서 자동 제공
# REDIS_URL은 환경 변수로 자동 주입됨