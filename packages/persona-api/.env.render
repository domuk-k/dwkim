# Render Production Environment

# Server Configuration
PORT=10000
NODE_ENV=production
LOG_LEVEL=info

# LLM Configuration  
OPENAI_MODEL=gpt-4.1-nano

# Rate Limiting (과금 방지)
RATE_LIMIT_MAX=50  # 분당 50회 (테스트 여유)
RATE_LIMIT_WINDOW_MS=60000

# OpenAI API 보호 (더 엄격)
MAX_TOKENS=300   # 토큰 수 더 제한 (비용 절약)
TEMPERATURE=0.5  # 더 일관된 응답 (변동성 감소)

# Mock 모드 (벡터 DB 없이 실행)
MOCK_MODE=true
USE_VECTOR_STORE=false

# Redis는 Render에서 자동 제공
# REDIS_URL은 환경 변수로 자동 주입됨